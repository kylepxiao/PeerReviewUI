Unnamed: 0	conference	paper_id	review_id	sentence_id	sentence	rating	decision	confidence
0	graph20	1	1	0	"""I have reviewed this paper earlier as a SIGGRAPH submission."	3	1	0.023896117
1	graph20	1	1	1	The paper presents a novel method based on deep learning to convert a rough stick figure, with joints drawn in a fixed pre-determined order, into a 3D human character in the intended shape.	3	1	0.014932183
2	graph20	1	1	2	As a representation for the 3D shape, the authors chose a point cloud.	3	1	0.015869392
3	graph20	1	1	3	The model has been trained on a tiny dataset (SCAPE), augmented with rotations.	3	1	0.018754749
4	graph20	1	1	4	The architecture of the network is based on an autoencoder: a variational autoencoder learns the latent representation of the 3D point clouds for various poses, and a regular encoder learns a mapping from the 2D stick figure into the latent space.	3	1	0.013475007
5	graph20	1	1	5	The paper is validated in various ways: doing the sketch-based posing of the character, pose interpolation, etc. Since the SIGGRAPH submission, I was glad to see that the most important non-technical bits were done, such as missing references etc. Overall, the paper is in a good shape and easy to read.	3	1	0.992512
6	graph20	1	1	6	The results are not stellar, but certainly a worthy investigation.	3	1	0.99308944
7	graph20	1	1	7	The model clearly has issues learning the latent space, because the dataset is so small, but it's still an interesting approach.	3	1	0.99183136
8	graph20	1	1	8	Moreover, I think this area of sketch-based posing is largely underdeveloped, so I welcome contributions like this.	3	1	0.49842885
9	graph20	1	1	9	My only comment is really the lack of details in 4.4: how the models are visualized.	3	1	0.99139506
10	graph20	1	1	10	Since the network outputs a point cloud, the authors combine it with the meshes from SCAPE, but I would like more details on how.	3	1	0.025254443
11	graph20	1	1	11	"Also, L797: ""fat"" -> ""obese""."	3	1	0.021405628
12	graph20	1	1	12	"I would also rethink the intro sentence ""Despite the increasing number of talented artists"" - not sure if that's what the authors intend to say really."	3	1	0.9923021
13	graph20	1	1	13	"Other than that, I think the paper is ready for GI. """	3	1	0.98307157
14	graph20	1	2	0	"""The paper presents a system to obtain posed meshes of a human, based on input sketches of a stick figure."	3	1	0.011248674
15	graph20	1	2	1	The method employs a neural network (VAE) to learn a latent space relating stick figures and meshes.	3	1	0.011166805
16	graph20	1	2	2	The latent space can also be used to interpolate between poses.	3	1	0.014567997
17	graph20	1	2	3	Since I am not an expert on neural networks, I can not judge the network architecture, however, it seems to follow well-established design principles.	3	1	0.99103236
18	graph20	1	2	4	The paper is well written and good to follow.	3	1	0.99294233
19	graph20	1	2	5	There are only a few grammar issues that can easily be resolved.	3	1	0.9912174
20	graph20	1	2	6	The figures are a little hard to see.	3	1	0.9953059
21	graph20	1	2	7	Maybe less intermediate steps (e.g. Figure 8) but larger images would be a good idea to make the differences between results more apparent.	3	1	0.96273345
22	graph20	1	2	8	The method relies on the SCAPE dataset and is limited to a specific character at a time given at different poses.	3	1	0.016411027
23	graph20	1	2	9	The posed models have to be meshed consistently and specific landmark points defining a skeleton have been identified beforehand.	3	1	0.9688055
24	graph20	1	2	10	I argue that this is enough information to easily find blend skinning weights and pose the character directly.	3	1	0.020452691
25	graph20	1	2	11	In other words, the main problem has already been solved in this dataset.	3	1	0.09041512
26	graph20	1	2	12	Of course one can argue that a stick figure is easier to draw and that automatic skinning has to be performed, however, compared to the 2 days of network training for just one specific model, this seems to be the better option.	3	1	0.6091556
27	graph20	1	2	13	Moreover, the method shows severe artifacts, e.g. the head in Fig. 5, second row.	3	1	0.82804745
28	graph20	1	2	14	Furthermore, if skinning weights are available, the matching could also be performed between 2d and 3d stick figures which appears to be much simpler.	3	1	0.061207842
29	graph20	1	2	15	That said, while quite limited, the method is still an innovative approach to a real problem and the paper could stimulate more research in this direction.	3	1	0.99231374
30	graph20	1	2	16	"Therefore I wouldn't argue against accepting the paper. """	3	1	0.42054182
31	graph20	1	3	0	"""This paper proposes a method to convert single-view 2D skeleton sketches to 3D human body poses based on VAE network architecture."	2	1	0.011793221
32	graph20	1	3	1	The interface is easy to use.	2	1	0.95830685
33	graph20	1	3	2	The paper was generally well-written and clear.	2	1	0.9941398
34	graph20	1	3	3	But in my opinion, the results are not of high quality and the comparisons are not convincing enough.	2	1	0.9926936
35	graph20	1	3	4	I intend to weakly reject the paper.	2	1	0.052801535
36	graph20	1	3	5	Some comments - The input sketch/skeleton should be exactly the same when compared to [Kanazawa et al. 2018] in Section 5.2.	2	1	0.9905275
37	graph20	1	3	6	- The output of the sketch-based face modeling system [Han et al. 2017] is with fine details.	2	1	0.9916496
38	graph20	1	3	7	So the production time is not comparable to this paper.	2	1	0.9922922
39	graph20	1	3	8	And it is noticeable that the model inference based on their deep regression network takes 50ms, which is much faster than 1 second in this paper.	2	1	0.99016297
40	graph20	1	3	9	- The training dataset is quite small (only 72 poses) and the network produces incompatible 3D models with sketch inputs that are not closely represented in the dataset.	2	1	0.47574595
41	graph20	1	3	10	And the interface provides no additional editing function to achieve the desired model when the direct output is not satisfactory.	2	1	0.98694175
42	graph20	1	3	11	"The application of this paper is relatively limited. """	2	1	0.9930532
43	graph20	2	1	0	"""This paper explores the design of user interfaces (UIs) for visual guidance in the context of interactive and navigate-able 360 degree virtual reality (VR) systems."	2	0	0.00861624
44	graph20	2	1	1	They present and describe a software system that enables the interactive and navigate-able 360 degree VR environment, within which they implemented four visual guidance UI techniques.	2	0	0.014253709
45	graph20	2	1	2	Overall the research objective seems interesting, but I would have appreciated a clearer overall presentation of the research and the specific contributions, and a clearer motivation of the research gap.	2	0	0.99069566
46	graph20	2	1	3	I also believe that the the study design holds some potential flaws that need addressing.	2	0	0.07991152
47	graph20	2	1	4	The introduction mixes in some lists of related work that would be better suited in the respectively named section; instead, a clear and focused motivation of the research gap being explored here would benefit the paper.	2	0	0.9928865
48	graph20	2	1	5	The authors motivate the system a little bit, but not so much the visual guidance UI.	2	0	0.992904
49	graph20	2	1	6	I think it would be very helpful as well if the introduction provided a summary of the paper's contributions.	2	0	0.9116648
50	graph20	2	1	7	This would also help to assess whether the number of pages is well matched to the size of the contribution.	2	0	0.012616338
51	graph20	2	1	8	"Although the end of the introduction seems to focus more on the study (as does the Discussion), I am pretty sure that the authors are presenting the RealNodes software system as part of the main contributions, as the paper goes into a lot of detail on this - to clarify, I agree that this can represent a contribution, however the section in which this is described could use some more general / abstract overview information before deep-diving into the specifics, and some more ""sign-posting"" in the text's structure."	2	0	0.993822
52	graph20	2	1	9	"In particular, I think that ""3.4 - Visual Guidance User Interface Methods"" should get more focus compared to the other aspects, as they represent the focus of the study presented in the paper, as opposed to the interaction objects and scenarios that are then described in detail in 3.5 & 3.6."	2	0	0.9866265
53	graph20	2	1	10	A clearer summary of the systems' overall benefits as well as a bit more motivation on why *these* four UI visual guidance techniques were chosen for the system would also be helpful.	2	0	0.9928157
54	graph20	2	1	11	The related work addresses navigation techniques, wayfinding guidance, visual transitions, and interactive elements.	2	0	0.013651925
55	graph20	2	1	12	These are largely presented as as a list; the paper would be stronger if it provided a bit more of a summary that outlines the research gap addressed by the authors.	2	0	0.99307305
56	graph20	2	1	13	Study: In an experimental within-subjects user study (N=24), the paper explores effects of four different UI techniques on engagement, simulator sickness, and completion time.	2	0	0.009511883
57	graph20	2	1	14	Some general notes: - participants' ages are not reported.	2	0	0.1205081
58	graph20	2	1	15	gender distribution could be a bit better.	2	0	0.99211854
59	graph20	2	1	16	prior VR experience not reported.	2	0	0.4241222
60	graph20	2	1	17	- UI techniques were counterbalanced, but were the hiding spots counter-balanced as well?	2	0	0.9906696
61	graph20	2	1	18	- effect sizes are not reported - some of the descriptive data reported in-text would be better suited for display in a table - what is the scale of the SSQ, does it only go up to 3.5 as indicated by Fig.17?	2	0	0.989563
62	graph20	2	1	19	If so, then the nausea scores aren't that great for any of the conditions.	2	0	0.48716506
63	graph20	2	1	20	- similarly, what is the scale range of the UES SF?	2	0	0.9928528
64	graph20	2	1	21	"Finally, and most importantly, the discussion then states: ""Arrow is unique compared to the other UIs in that it stays active on screen."""	2	0	0.6919648
65	graph20	2	1	22	Before this statement, it was not clear to me that the Path technique was not visible continuously.	2	0	0.80617106
66	graph20	2	1	23	If only Arrow is continuously shown, then the study design seems unbalanced, comparing 1 continuous wayfinding techniques with 3 discrete target marking techniques.	2	0	0.9927451
67	graph20	2	1	24	That Arrow then leads to significantly faster completion times hardly seems surprising.	2	0	0.9934256
68	graph20	2	1	25	Overall, I find that the potentially unbalanced design and the missing information in the study (particularly the effect sizes) make it very hard to judge what is being investigated here.	2	0	0.992376
69	graph20	2	1	26	Without addressing these issues, I do not think that this submission is quite ready for publication.	2	0	0.9837635
70	graph20	2	1	27	"Minor points: - ""reignited"" -> ""re-ignited"" - ""[21] [2]"" -> bibentry21, bibentry2 -> [2, 21] (can use a parameter for the package to tell LaTeX to auto-sort the citations) - ""demonstrates how we build upon and differentiates from prior research"" -> ""and differentiate our work from..."" - Fig."	2	0	0.030269796
71	graph20	2	1	28	"1 is a nice overview but also to a degree redundant with Fig.5, Fig.6, Fig. 7, and Fig.8"""	2	0	0.9922858
72	graph20	2	2	0	"""#== SUMMARY ==# The authors present RealNodes."	2	0	0.018287033
73	graph20	2	2	1	VR users can freely look around in a pre-recorded 360 video.	2	0	0.022581363
74	graph20	2	2	2	Multiple 360 videos are shot at different key locations.	2	0	0.020122422
75	graph20	2	2	3	Users can navigate between them using gaze direction and walking in place to simulate moving to different locations in space.	2	0	0.017626463
76	graph20	2	2	4	For each 360 video, particular gaze directions are mapped to different pre-defined paths available for navigation.	2	0	0.01050949
77	graph20	2	2	5	The system provides visual guidance to communicate, which directions the users can move to from their position.	2	0	0.021304308
78	graph20	2	2	6	The authors compared four different visual aids and found significant differences between the techniques in terms of completion time and preference.	2	0	0.014576023
79	graph20	2	2	7	In the paper, the authors describe the implementation of the system and report the study results.	2	0	0.008935886
80	graph20	2	2	8	#== REVIEW ==# The authors present a well made system with a nicely executed study.	2	0	0.98463076
81	graph20	2	2	9	The paper is well written and easy to follow.	2	0	0.9943621
82	graph20	2	2	10	However, there are issues with the novelty and generalizability of the results.	2	0	0.99246585
83	graph20	2	2	11	In the following, I would like to elaborate on those issues.	2	0	0.13035208
84	graph20	2	2	12	The amount of related work is somewhat sparse, but there are some places in which related work is incorporated well to inform the design.	2	0	0.994493
85	graph20	2	2	13	For instance, the guidance techniques are inspired by previous work.	2	0	0.7576049
86	graph20	2	2	14	"However, other parts, like the claimed ""novel additions"" or ""novel changes"" in section 3 are not backed by related work."	2	0	0.9952876
87	graph20	2	2	15	"In fact, those claimed ""novelties"" are just specific ways of implementing the desired system by customizing existing assets."	2	0	0.012749367
88	graph20	2	2	16	Therefore, they have no novelty from a research perspective and, again, not positioning them in literature makes those claims entirely unfounded.	2	0	0.9939369
89	graph20	2	2	17	For instance, using three textures as the environment map and combining them, e.g., through blending is described as novel, but this is just a specific way of implementing the desired effect.	2	0	0.9805772
90	graph20	2	2	18	Therefore, while the implementation is well made, there is no contribution from a technical perspective.	2	0	0.9936443
91	graph20	2	2	19	The descriptions about the implementation details can be shortened and the concept can be explained in more general terms than describing it around Unity3D assets.	2	0	0.9893056
92	graph20	2	2	20	Furthermore, implementation details like for instance preloading videos into memory are not essential for reproducibility.	2	0	0.9916316
93	graph20	2	2	21	That said, the description about synchronizing the walking speed (i.e., the oscillation of the HMD) with the video playback is the most interesting of the presented ideas.	2	0	0.9922847
94	graph20	2	2	22	However, this part is not fleshed out and ends up as another minor addition or implementation detail, even though it might have some potential to be explored more in depth.	2	0	0.9928747
95	graph20	2	2	23	The study is well designed and executed.	2	0	0.99299514
